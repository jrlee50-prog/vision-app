import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
from datetime import datetime

st.set_page_config(
    page_title="Vision Web App",
    page_icon="ğŸ‘ï¸",
    layout="wide"
)

st.title("ğŸ‘ï¸ Vision Web App")
st.markdown("### ì–¼êµ´ ì¸ì‹ & ê°ì²´ íƒì§€ ì›¹ì•±")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'known_faces' not in st.session_state:
    st.session_state.known_faces = {}

# ì‚¬ì´ë“œë°” ë©”ë‰´
menu = st.sidebar.selectbox(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ  í™ˆ", "ğŸ“¹ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°(webrtc)", "ğŸ“¸ ì›¹ìº (ìŠ¤ëƒ…ìƒ·)", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„", "ğŸ‘¤ ì–¼êµ´ ë“±ë¡", "ğŸ“š ì‚¬ìš©ë²•"]
)

def detect_faces_opencv(image):
    """OpenCVë¡œ ì–¼êµ´ íƒì§€"""
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
    
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)
    
    return image, len(faces)

def detect_objects_opencv(image):
    """OpenCV DNNìœ¼ë¡œ ê°ì²´ íƒì§€"""
    try:
        config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
        frozen_model = 'frozen_inference_graph.pb'
        
        if os.path.exists(config_file) and os.path.exists(frozen_model):
            model = cv2.dnn_DetectionModel(frozen_model, config_file)
            model.setInputSize(320, 320)
            model.setInputScale(1.0/127.5)
            model.setInputMean((127.5, 127.5, 127.5))
            model.setInputSwapRB(True)
            
            class_labels = []
            if os.path.exists('Labels.txt'):
                with open('Labels.txt', 'rt') as f:
                    class_labels = f.read().rstrip('\n').split('\n')
            
            ClassIndex, confidence, bbox = model.detect(image, confThreshold=0.5)
            
            if len(ClassIndex) != 0:
                for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
                    if ClassInd <= 80 and len(class_labels) >= ClassInd:
                        cv2.rectangle(image, boxes, (255, 0, 0), 2)
                        label = class_labels[ClassInd-1] if len(class_labels) >= ClassInd else f"Class {ClassInd}"
                        cv2.putText(image, label, 
                                   (boxes[0]+10, boxes[1]+40), 
                                   cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)
        else:
            st.warning("ê°ì²´ íƒì§€ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ê°ì²´ íƒì§€ ì˜¤ë¥˜: {e}")
    
    return image

if menu == "ğŸ  í™ˆ":
    st.markdown("""
    ## í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‘‹
    
    ì´ ì›¹ì•±ì€ **OpenCV**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
    
    ### âœ¨ ì£¼ìš” ê¸°ëŠ¥
    - ğŸ“¸ **ì‹¤ì‹œê°„ ì›¹ìº **: ì¹œêµ¬ ì–¼êµ´ íƒì§€ ë° ê°ì²´ ì¸ì‹
    - ğŸ–¼ï¸ **ì´ë¯¸ì§€ ë¶„ì„**: ì—…ë¡œë“œí•œ ì‚¬ì§„ ë¶„ì„
    - ğŸ‘¤ **ì–¼êµ´ ë“±ë¡**: ìƒˆë¡œìš´ ì–¼êµ´ ë“±ë¡ ë° ê´€ë¦¬
    
    ### ğŸ“± ì–´ë””ì„œë“  ì‚¬ìš© ê°€ëŠ¥
    - PC, íƒœë¸”ë¦¿, ìŠ¤ë§ˆíŠ¸í° ëª¨ë‘ ì§€ì›
    - ì›¹ ë¸Œë¼ìš°ì €ë§Œ ìˆìœ¼ë©´ OK!
    
    ### ğŸš€ ì‹œì‘í•˜ê¸°
    ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”!
    """)

elif menu == "ğŸ“¹ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°(webrtc)":
    st.header("ğŸ“¹ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°(webrtc)")
    st.caption("ë¸Œë¼ìš°ì € ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•´. (ì§„ì§œ ì‹¤ì‹œê°„)")

    # streamlit-webrtcëŠ” import ë¹„ìš©ì´ ì¢€ ìˆì–´ì„œ ì—¬ê¸°ì„œ import
    from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
    import av

    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì–¼êµ´ íƒì§€", "ê°ì²´ íƒì§€"], horizontal=True)

    col1, col2 = st.columns(2)
    with col1:
        conf = st.slider("ê°ì²´ íƒì§€ confThreshold", 0.1, 0.9, 0.5, 0.05)
    with col2:
        face_scale = st.slider("ì–¼êµ´ íƒì§€ scaleFactor", 1.05, 1.5, 1.10, 0.01)

    class Processor(VideoProcessorBase):
        def __init__(self):
            self.face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            )

        def recv(self, frame):
            img = frame.to_ndarray(format="bgr24")

            if mode == "ì–¼êµ´ íƒì§€":
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                faces = self.face_cascade.detectMultiScale(gray, face_scale, 4)
                for (x, y, w, h) in faces:
                    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)
                cv2.putText(img, f"faces: {len(faces)}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
            else:
                # ê¸°ì¡´ í•¨ìˆ˜ëŠ” íŒŒì¼ ì¡´ì¬ì—¬ë¶€ ë“± Streamlit UIì— ê²½ê³ ë¥¼ ë„ìš°ê¸° ë•Œë¬¸ì—
                # ì‹¤ì‹œê°„ì—ì„œëŠ” ì•„ì£¼ ë‹¨ìˆœíˆ 'ëª¨ë¸íŒŒì¼ ìˆìœ¼ë©´'ë§Œ ì²˜ë¦¬
                try:
                    config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
                    frozen_model = 'frozen_inference_graph.pb'
                    if os.path.exists(config_file) and os.path.exists(frozen_model):
                        model = cv2.dnn_DetectionModel(frozen_model, config_file)
                        model.setInputSize(320, 320)
                        model.setInputScale(1.0/127.5)
                        model.setInputMean((127.5, 127.5, 127.5))
                        model.setInputSwapRB(True)
                        ClassIndex, confidence, bbox = model.detect(img, confThreshold=float(conf))
                        if len(ClassIndex) != 0:
                            for ClassInd, c, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
                                cv2.rectangle(img, boxes, (0, 255, 0), 2)
                                cv2.putText(img, f"{int(ClassInd)} {c:.2f}", (boxes[0], max(0, boxes[1]-10)),
                                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    else:
                        cv2.putText(img, "(object model missing)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                except Exception:
                    cv2.putText(img, "object detect error", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

            return av.VideoFrame.from_ndarray(img, format="bgr24")

    webrtc_streamer(
        key="realtime",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=Processor,
        media_stream_constraints={"video": True, "audio": False},
        rtc_configuration={
            "iceServers": [
                {"urls": ["stun:stun.l.google.com:19302", "stun:stun1.l.google.com:19302"]}
            ]
        },
        video_html_attrs={"autoPlay": True, "muted": True, "playsInline": True},
        desired_playing_state=True,
        async_processing=True,
    )

    st.info("ì¹´ë©”ë¼ ê¶Œí•œ í—ˆìš©í•˜ë©´ ë°”ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë”°ë¼ê°€. ëŠê¸°ë©´ ìƒˆë¡œê³ ì¹¨(F5)í•˜ë©´ ë¼.")

elif menu == "ğŸ“¸ ì›¹ìº (ìŠ¤ëƒ…ìƒ·)":
    st.header("ğŸ“¸ ì›¹ìº (ìŠ¤ëƒ…ìƒ·)")
    
    mode = st.radio("ëª¨ë“œ ì„ íƒ", ["ì–¼êµ´ íƒì§€", "ê°ì²´ íƒì§€"])
    
    # ì›¹ìº  ì…ë ¥
    camera_image = st.camera_input("ì›¹ìº ìœ¼ë¡œ ì‚¬ì§„ ì°ê¸°")
    
    if camera_image is not None:
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        bytes_data = camera_image.getvalue()
        cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
        
        if mode == "ì–¼êµ´ íƒì§€":
            result_img, face_count = detect_faces_opencv(cv2_img)
            st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), 
                    caption=f"íƒì§€ëœ ì–¼êµ´: {face_count}ê°œ")
        else:
            result_img = detect_objects_opencv(cv2_img)
            st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), 
                    caption="ê°ì²´ íƒì§€ ê²°ê³¼")
        
        # ê²°ê³¼ ì €ì¥
        if st.button("ğŸ’¾ ê²°ê³¼ ì €ì¥"):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"output/result_{timestamp}.jpg"
            os.makedirs("output", exist_ok=True)
            cv2.imwrite(filename, result_img)
            st.success(f"ì €ì¥ ì™„ë£Œ: {filename}")

elif menu == "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„":
    st.header("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„")
    
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['jpg', 'jpeg', 'png'])
    
    if uploaded_file is not None:
        # ì´ë¯¸ì§€ í‘œì‹œ
        image = Image.open(uploaded_file)
        st.image(image, caption="ì›ë³¸ ì´ë¯¸ì§€", use_column_width=True)
        
        # ë¶„ì„ ëª¨ë“œ ì„ íƒ
        analysis_mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["ì–¼êµ´ íƒì§€", "ê°ì²´ íƒì§€"])
        
        if st.button("ğŸ” ë¶„ì„ ì‹œì‘"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                # OpenCVìš©ìœ¼ë¡œ ë³€í™˜
                img_array = np.array(image)
                cv2_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                
                if analysis_mode == "ì–¼êµ´ íƒì§€":
                    result_img, face_count = detect_faces_opencv(cv2_img)
                    st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), 
                            caption=f"íƒì§€ëœ ì–¼êµ´: {face_count}ê°œ")
                    
                    if face_count > 0:
                        st.success(f"âœ… {face_count}ê°œì˜ ì–¼êµ´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    else:
                        st.warning("ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    result_img = detect_objects_opencv(cv2_img)
                    st.image(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB), 
                            caption="ê°ì²´ íƒì§€ ê²°ê³¼")

elif menu == "ğŸ‘¤ ì–¼êµ´ ë“±ë¡":
    st.header("ğŸ‘¤ ì–¼êµ´ ë“±ë¡")
    
    st.markdown("""
    ìƒˆë¡œìš´ ì–¼êµ´ì„ ë“±ë¡í•©ë‹ˆë‹¤. ì›¹ìº ìœ¼ë¡œ ì´¬ì˜í•˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.
    """)
    
    name = st.text_input("ì´ë¦„ ì…ë ¥")
    
    register_method = st.radio("ë“±ë¡ ë°©ë²•", ["ì›¹ìº ìœ¼ë¡œ ì´¬ì˜", "ì´ë¯¸ì§€ ì—…ë¡œë“œ"])
    
    if register_method == "ì›¹ìº ìœ¼ë¡œ ì´¬ì˜":
        camera_image = st.camera_input("ì–¼êµ´ì„ ë³´ì—¬ì£¼ê³  ì´¬ì˜í•˜ì„¸ìš”")
        if camera_image is not None and name:
            if st.button("ë“±ë¡í•˜ê¸°"):
                os.makedirs("known_faces", exist_ok=True)
                with open(f"known_faces/{name}.jpg", "wb") as f:
                    f.write(camera_image.getvalue())
                st.success(f"âœ… {name}ë‹˜ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        uploaded_file = st.file_uploader("ì–¼êµ´ ì‚¬ì§„ ì—…ë¡œë“œ", type=['jpg', 'jpeg', 'png'])
        if uploaded_file is not None and name:
            if st.button("ë“±ë¡í•˜ê¸°"):
                os.makedirs("known_faces", exist_ok=True)
                with open(f"known_faces/{name}.jpg", "wb") as f:
                    f.write(uploaded_file.getvalue())
                st.success(f"âœ… {name}ë‹˜ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ë“±ë¡ëœ ì–¼êµ´ ëª©ë¡
    st.subheader("ë“±ë¡ëœ ì–¼êµ´ ëª©ë¡")
    if os.path.exists("known_faces"):
        faces = os.listdir("known_faces")
        if faces:
            for face in faces:
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write(f"ğŸ‘¤ {face.replace('.jpg', '').replace('.png', '')}")
                with col2:
                    if st.button("ì‚­ì œ", key=face):
                        os.remove(f"known_faces/{face}")
                        st.experimental_rerun()
        else:
            st.info("ë“±ë¡ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.")

elif menu == "ğŸ“š ì‚¬ìš©ë²•":
    st.header("ğŸ“š ì‚¬ìš©ë²•")
    
    st.markdown("""
    ### ğŸ¯ ë¹ ë¥¸ ì‹œì‘
    
    1. **ğŸ“¸ ì‹¤ì‹œê°„ ì›¹ìº **
       - 'ì›¹ìº ìœ¼ë¡œ ì‚¬ì§„ ì°ê¸°' ë²„íŠ¼ í´ë¦­
       - ì–¼êµ´ì´ë‚˜ ê°ì²´ë¥¼ ì¹´ë©”ë¼ì— ë³´ì—¬ì£¼ì„¸ìš”
       - ìë™ìœ¼ë¡œ íƒì§€ë©ë‹ˆë‹¤!
    
    2. **ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„**
       - ë¶„ì„í•  ì‚¬ì§„ì„ ì—…ë¡œë“œ
       - 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ í´ë¦­
       - ê²°ê³¼ í™•ì¸!
    
    3. **ğŸ‘¤ ì–¼êµ´ ë“±ë¡**
       - ì´ë¦„ ì…ë ¥
       - ì›¹ìº  ë˜ëŠ” ì´ë¯¸ì§€ë¡œ ë“±ë¡
       - ë“±ë¡ëœ ì–¼êµ´ì€ ëª©ë¡ì—ì„œ ê´€ë¦¬
    
    ### ğŸ’¡ íŒ
    - ë°ì€ ê³³ì—ì„œ ì‚¬ìš©í•˜ë©´ ë” ì˜ ì¸ì‹ë©ë‹ˆë‹¤
    - ì–¼êµ´ì€ ì •ë©´ìœ¼ë¡œ ë³´ì—¬ì£¼ì„¸ìš”
    - ì—¬ëŸ¬ ì‚¬ëŒì´ ìˆì–´ë„ ëª¨ë‘ íƒì§€ë©ë‹ˆë‹¤
    
    ### ğŸ”’ ê°œì¸ì •ë³´ ë³´í˜¸
    - ëª¨ë“  ë°ì´í„°ëŠ” ë¡œì»¬ì— ì €ì¥ë©ë‹ˆë‹¤
    - ì™¸ë¶€ ì„œë²„ë¡œ ì „ì†¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤
    """)

# í‘¸í„°
st.sidebar.markdown("---")
st.sidebar.markdown("Made with â¤ï¸ using Streamlit & OpenCV")
