import cv2
import face_recognition
import numpy as np
import os
from datetime import datetime


class VisionApp:
    def __init__(self):
        self.known_face_encodings = []
        self.known_face_names = []
        self.camera = None
        
    def add_known_face(self, image_path, name):
        """Îì±Î°ùÎêú ÏñºÍµ¥ Ï∂îÍ∞Ä"""
        image = face_recognition.load_image_file(image_path)
        encoding = face_recognition.face_encodings(image)[0]
        self.known_face_encodings.append(encoding)
        self.known_face_names.append(name)
        print(f"Îì±Î°ù ÏôÑÎ£å: {name}")
        
    def recognize_faces(self, frame):
        """ÏñºÍµ¥ Ïù∏Ïãù ÏàòÌñâ"""
        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
        
        face_names = []
        for face_encoding in face_encodings:
            matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)
            name = "Unknown"
            
            if True in matches:
                first_match_index = matches.index(True)
                name = self.known_face_names[first_match_index]
            
            face_names.append(name)
            
        for (top, right, bottom, left), name in zip(face_locations, face_names):
            top *= 4
            right *= 4
            bottom *= 4
            left *= 4
            
            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.8, (255, 255, 255), 1)
            
        return frame
    
    def detect_objects_yolo(self, frame):
        """YOLOÎ°ú Í∞ùÏ≤¥ ÌÉêÏßÄ"""
        try:
            from ultralytics import YOLO
            model = YOLO('yolov8n.pt')
            results = model(frame)
            annotated_frame = results[0].plot()
            return annotated_frame
        except ImportError:
            return self.detect_objects_opencv(frame)
    
    def detect_objects_opencv(self, frame):
        """OpenCV DNNÏúºÎ°ú Í∞ùÏ≤¥ ÌÉêÏßÄ (YOLO ÏóÜÏùÑ Îïå)"""
        try:
            config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
            frozen_model = 'frozen_inference_graph.pb'
            
            if not os.path.exists(config_file) or not os.path.exists(frozen_model):
                cv2.putText(frame, "Model files not found. Run setup_models.py", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                return frame
            
            model = cv2.dnn_DetectionModel(frozen_model, config_file)
            model.setInputSize(320, 320)
            model.setInputScale(1.0/127.5)
            model.setInputMean((127.5, 127.5, 127.5))
            model.setInputSwapRB(True)
            
            classLabels = []
            file_name = 'Labels.txt'
            with open(file_name, 'rt') as fpt:
                classLabels = fpt.read().rstrip('\n').split('\n')
            
            ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.5)
            
            if len(ClassIndex) != 0:
                for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
                    if ClassInd <= 80:
                        cv2.rectangle(frame, boxes, (255, 0, 0), 2)
                        cv2.putText(frame, classLabels[ClassInd-1], 
                                   (boxes[0]+10, boxes[1]+40), 
                                   cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)
        except Exception as e:
            cv2.putText(frame, f"Object detection error: {str(e)}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        return frame
    
    def start_webcam(self, mode='face'):
        """ÏõπÏ∫† ÏãúÏûë
        mode: 'face' = ÏñºÍµ¥ Ïù∏Ïãù, 'object' = Í∞ùÏ≤¥ ÌÉêÏßÄ
        """
        self.camera = cv2.VideoCapture(0)
        
        if not self.camera.isOpened():
            print("ÏõπÏ∫†ÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§!")
            return
        
        print(f"ÏõπÏ∫† ÏãúÏûë - Î™®Îìú: {mode}")
        print("Ï¢ÖÎ£åÌïòÎ†§Î©¥ 'q'Î•º ÎàÑÎ•¥ÏÑ∏Ïöî")
        
        while True:
            ret, frame = self.camera.read()
            if not ret:
                break
            
            frame = cv2.flip(frame, 1)
            
            if mode == 'face':
                frame = self.recognize_faces(frame)
            elif mode == 'object':
                frame = self.detect_objects_yolo(frame)
            
            cv2.imshow('Vision App', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        self.camera.release()
        cv2.destroyAllWindows()
    
    def process_image(self, image_path, mode='face', output_path=None):
        """Ïù¥ÎØ∏ÏßÄ ÌååÏùº Ï≤òÎ¶¨"""
        frame = cv2.imread(image_path)
        
        if frame is None:
            print(f"Ïù¥ÎØ∏ÏßÄÎ•º Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§: {image_path}")
            return
        
        if mode == 'face':
            frame = self.recognize_faces(frame)
        elif mode == 'object':
            frame = self.detect_objects_yolo(frame)
        
        if output_path:
            cv2.imwrite(output_path, frame)
            print(f"Í≤∞Í≥º Ï†ÄÏû•: {output_path}")
        
        cv2.imshow('Result', frame)
        cv2.waitKey(0)
        cv2.destroyAllWindows()


if __name__ == "__main__":
    app = VisionApp()
    
    print("=" * 50)
    print("üé• ÎπÑÏ†Ñ ÌîÑÎ°úÍ∑∏Îû®")
    print("=" * 50)
    print("1. ÏõπÏ∫† - ÏñºÍµ¥ Ïù∏Ïãù")
    print("2. ÏõπÏ∫† - Í∞ùÏ≤¥ ÌÉêÏßÄ")
    print("3. Ïù¥ÎØ∏ÏßÄ ÌååÏùº Ï≤òÎ¶¨")
    print("4. Ï¢ÖÎ£å")
    print("=" * 50)
    
    choice = input("ÏÑ†ÌÉù: ")
    
    if choice == '1':
        app.start_webcam(mode='face')
    elif choice == '2':
        app.start_webcam(mode='object')
    elif choice == '3':
        image_path = input("Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú: ")
        mode = input("Î™®Îìú (face/object): ")
        app.process_image(image_path, mode=mode)
    else:
        print("Ï¢ÖÎ£åÌï©ÎãàÎã§.")